{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Copy of Copy of NB19_Redes_Neurais__V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MathMachado/DSWP/blob/master/Notebooks/NB19_Redes_Neurais__Aubay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ShVXyGj9wkgN"
      },
      "source": [
        "<center><h1><b><i>REDES NEURAIS ARTIFICIAIS (COMPREHENSIVE GUIDE) </i></b></h1></center>\n",
        "\n",
        "# Porque Cientistas de Dados desejam aprender e dominar Redes Neurais?\n",
        "\n",
        "* Redes Neurais têm a capacidade de aprender, modelar e resolver problemas não-lineares e complexos apresentados pela vida real.\n",
        "* Você já deve ter ouvido falar em Inteligência Artificial, _self-drive cars_, _Deep Learning_, _Computer Vision_ e _Neural Language Processing_ (NLP). Todos estes assuntos estão estreitamente relacionados às Redes Neurais. Por exemplo, _Deep Learning_ são Redes Neurais com muitas _Hidden Layers_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QgX6n2VDyY1O"
      },
      "source": [
        "___\n",
        "# **REFERÊNCIAS**\n",
        "- [An Introduction to Neural Networks](http://www.cs.stir.ac.uk/~lss/NNIntro/InvSlides.html)\n",
        "- [An Introduction to Image Recognition with Deep Learning](https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721)\n",
        "- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)\n",
        "- [Forward propagation in neural networks — Simplified math and code version](https://towardsdatascience.com/forward-propagation-in-neural-networks-simplified-math-and-code-version-bbcfef6f9250)\n",
        "- [Understanding Neural Networks: From Activation Function To Back Propagation](https://medium.com/fintechexplained/neural-networks-activation-function-to-back-propagation-understanding-neural-networks-bdd036c3f29f)\n",
        "- [Understanding Gradient Descent](https://medium.com/analytics-vidhya/understanding-gradient-descent-8dd88a4c60e6) - Explica detalhadamente como funciona o _Gradient Descent_ no processo de otimização dos pesos $W$;\n",
        "- [Backpropagation step by step](https://medium.com/swlh/backpropagation-step-by-step-13f2b6c0b414) - Eu usei esse artigo para reajustar os pesos $W$;\n",
        "- [Perceptron Learning Algorithm: A Graphical Explanation Of Why It Works](https://towardsdatascience.com/perceptron-learning-algorithm-d5db0deab975);\n",
        "- [Math behind Perceptrons](https://medium.com/@iamask09/math-behind-perceptrons-7241d5dadbfc);\n",
        "- [Neural Network: A Complete Beginners Guide from Scratch](https://medium.com/gadictos/neural-network-a-complete-beginners-guide-from-scratch-cf1fc9d5cd12);\n",
        "- [Calculating the Backpropagation of a Network](https://medium.com/towards-artificial-intelligence/calculating-back-propagation-of-a-network-1febbcaa2b5d);\n",
        "- [Let’s build a simple Neural Net!](https://becominghuman.ai/lets-build-a-simple-neural-net-f4474256647f) - O autor constroi uma Rede Neural simples, sem _Hidden Layers_;\n",
        "- [Coding Neural Network — Forward Propagation and Backpropagtion](https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76);\n",
        "- [The Simplest Neural Network: Understanding the non-linearity](https://towardsdatascience.com/the-simplest-neural-network-understanding-the-non-linearity-10846d7d0141) - Ótimo texto para entender a não-linearidade;\n",
        "- [Implementing the XOR Gate using Backpropagation in Neural Networks](https://towardsdatascience.com/implementing-the-xor-gate-using-backpropagation-in-neural-networks-c1f255b4f20d) - Usei este texto para resolver o problema do XOR;\n",
        "- [Neural Representation of AND, OR, NOT, XOR and XNOR Logic Gates (Perceptron Algorithm)](https://medium.com/@stanleydukor/neural-representation-of-and-or-not-xor-and-xnor-logic-gates-perceptron-algorithm-b0275375fea1) - Eu usei este material para resolver o problema dos operadores E, OU e XOR;\n",
        "- [Solving XOR with a single Perceptron](https://medium.com/@lucaspereira0612/solving-xor-with-a-single-perceptron-34539f395182);\n",
        "- [Machine Learning 101 — Artificial Neural Networks](https://towardsdatascience.com/machine-learning-101-artificial-neural-networks-3-46ccb04cba30) - Cálculos realizados passo a passo;\n",
        "- [Neural Network from scratch in Python](https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65) - Este artigo mostra a matemática por trás das Redes Neurais;\n",
        "- [Classical Neural Net: Why/Which Activations Functions?](https://towardsdatascience.com/classical-neural-net-why-which-activations-functions-401159ba01c4) - Artigo que discute as principais funções de ativação;\n",
        "- [Understanding Activation Functions in Neural Networks](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0);\n",
        "- [Mind: How to Build a Neural Network (Part One)](https://becominghuman.ai/mind-how-to-build-a-neural-network-part-one-67b6aea4ce20);\n",
        "- [How to build a simple Neural Network from scratch with Python](https://towardsdatascience.com/how-to-build-a-simple-neural-network-from-scratch-with-python-9f011896d2f3);\n",
        "- [Comparison of Activation Functions for Deep Neural Networks](https://towardsdatascience.com/comparison-of-activation-functions-for-deep-neural-networks-706ac4284c8a);\n",
        "- [MAE and RMSE — Which Metric is Better?](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d) - Ótimo artigo, pois discute qual métrica é melhor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TsCbZd2epfxo"
      },
      "source": [
        "___\n",
        "# **INTRODUÇÃO ÀS REDES NEURAIS**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HqqB2vaHXMGt"
      },
      "source": [
        "* Redes Neurais aprendem com as experiências passadas, imitando o funcionamento dos neurônios humanos no processo de aprendizagem;\n",
        "* podem e são amplamente utilizadas nas seguintes situações (aplicações):\n",
        "    * Reconhecimento Facial;\n",
        "    * Processamento de Linguagem Natural (NLP);\n",
        "    * _Self-drive car_;\n",
        "    * Visão computacional;\n",
        "    * Detecção de padrões (doenças, tumores e etc) em imagens;\n",
        "* Ideal para o cenário onde temos muitos dados (_Big Data_) e para resolver problemas complexos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f_T35rXZOB4G"
      },
      "source": [
        "___\n",
        "# **REDES NEURAIS MULTICAMADA**\n",
        "\n",
        "* Pelo menos 1 _Hidden Layer_. Observe a Rede Neural a seguir contendo 20 neurônios distribuídos da seguinte forma:\n",
        "\n",
        "    * Número de neurônios na camada de entrada (_Input Layer_): 4;\n",
        "    * 3 camadas escondidas (_Hidden Layers_) com 5 neurônios cada, totalizando 15 neurônios:\n",
        "        * Número de neurônios na _Hidden Layer 1_: 5;\n",
        "        * Número de neurônios na _Hidden Layer 2_: 5;\n",
        "        * Número de neurônios na _Hidden Layer 3_: 5;\n",
        "    * Número de neurônios na camada de saída (_Output Layer_): 1;\n",
        "* _Fully connected layer_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dXBXuh2-Tuo",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/MathMachado/Materials/blob/master/RNA_Multicamada.png?raw=true\" alt=\"Drawing\" width= \"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK4O_Y_l2vev",
        "colab_type": "text"
      },
      "source": [
        "## Função _Sigmoid_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_nn8zELXEVf",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/MathMachado/Materials/blob/master/Sigmoid_Limite.png?raw=true\" alt=\"Drawing\" width= \"800\"/>\n",
        "\n",
        "Consulte [e (constante matemática)](https://pt.wikipedia.org/wiki/E_(constante_matem%C3%A1tica)) para saber mais sobre a constante de Euler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOWwWR7hOmir",
        "colab_type": "text"
      },
      "source": [
        "## Número de _Hidden Layers_\n",
        "\n",
        "Pesquisadores apontam que 1 única _Hidden Layer_ é suficiente para a grande maioria dos problemas e que usualmente cada _Hidden Layer_ possui o mesmo número de neurônios. Experimentos mostram que mais _Hidden Layers_ implica em maior tempo para treinar a Rede Neural. No entanto, [Heaton Research](https://www.heatonresearch.com/2017/06/01/hidden-layers.html), mostra que:\n",
        "\n",
        "![Determinining_number_Hidden_Layers](https://github.com/MathMachado/Materials/blob/master/Determinining_number_Hidden_Layers.png?raw=true)\n",
        "\n",
        "Fonte: [Heaton Research](https://www.heatonresearch.com/2017/06/01/hidden-layers.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4_1JCbcPRrn",
        "colab_type": "text"
      },
      "source": [
        "## Número de neurônios na camada de entrada (_Input Layer_): $N_{I}$\n",
        "\n",
        "$N_{I}$= Número de colunas (ou variáveis) no dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fk-lhwhffUZz"
      },
      "source": [
        "### Número de neurônios na camada de saída (_Output Layer_): $N_{O}$\n",
        "\n",
        "* Se a Rede Neural é uma regressão, então o número de neurônios na _Output Layer_ é 1, pois o _output_ de uma regressão é um valor;\n",
        "* Se a Rede Neural é uma classificação e usamos uma função de ativação probabilística (como _softmax_, por exemplo), então o número de neurônios na _Output Layer_ é igual ao número de classes que queremos prever. Por exemplo, no problema de classificar espécies no dataframe IRIS temos 3 espécies (versicolor, virginica e setosa). Ao utilizarmos a função de ativação _softmax_, então teremos 3 neurônios na _Output Layer_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZsrrdLpSfYm9"
      },
      "source": [
        "## Número de neurônios na camada escondida (_Hidden Layer_): $N_{H}$\n",
        "\n",
        "Determinar o número de neurônios na _Hidden Layer_ tem sido um exercício de tentativa e erro, mas alguns experimentos tem demonstrado que o número adequado de neurônios na _Hidden Layer_ pode ser obtido através da expressão a seguir:\n",
        "\n",
        "$$N_{H}= \\frac{N_{I}+N_{O}}{2}$$\n",
        "\n",
        "No entanto, o artigo [How to choose the number of hidden layers and nodes in a feedforward neural network?](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw) sugere o uso da seguinte expressão:\n",
        "\n",
        "$$N_H= \\frac{N}{\\alpha(N_{I}+N_{O})}$$\n",
        "\n",
        "onde $N$ é o número de instâncias (linhas) do dataframe e $\\alpha$ é um número entre 2 e 10, sendo que alguns experimentos com $\\alpha= 2$ produzem bons modelos sem _overfitting_. Para saber mais sobre esta expressão e sobre $\\alpha$, sugiro a leitura do artigo mencionado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuO2t22CffE8",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "# **Como as Redes Neurais aprendem?**\n",
        "\n",
        "> Vimos até agora grande parte dos cálculos matemáticos que envolvem o treinamento das Redes Neurais. Treinar Redes Neurais envolvem a repetição dos processos _Forward_ e _Backward_:\n",
        "\n",
        "1. _Forward_: Consiste na multiplicação de matrizes entre os _arrays_ da _input layer_, pesos $W$ e, na sequência, aplicar as funções de ativação.\n",
        "\n",
        "2. _Backward_: Consiste em atualizar os pesos $W_{O}$ e $W_{H}$ para minimizar a _Loss Function_ $L$ usando _Gradient Descent_.\n",
        "\n",
        "* Estes 2 processos foram vistos detalhadamente em aulas anteriores.\n",
        "    * Cálculos matemáticos passo a passo foram mostrados. Portanto, visite nossas aulas anteriores para aprender mais sobre os aspectos teóricos e matemáticos por trás das Redes Neurais.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/MathMachado/Materials/master/Forward_Backward.png?raw=true\" alt=\"Drawing\" width= \"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpKyqSuDdbMr",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "# **_GRADIENT DESCENT_**\n",
        "\n",
        "_Gradient Descent_ é um algoritmo interativo utilizado para otimizar (neste caso, minimizar) a _Loss Function_ $L$. \n",
        "\n",
        "* Minimizar a _Loss Function_ $L$ significa encontrar os pesos $W_{H}$ e $W_{O}$ que faz com que MSE seja o menor possível, pois quanto menor o MSE, melhor a performance da Rede Neural. \n",
        "\n",
        "* Para atualizar os pesos $W$, vamos usar a expressão a seguir:\n",
        "\n",
        "$$W_{n+1}= W_{n}*M+\\alpha \\frac{\\partial L}{\\partial W_{n}}= W_{n}*M+\\alpha*(X*\\Delta)$$\n",
        "\n",
        "onde:\n",
        "\n",
        "* $L$ é a _Loss Function_ a ser minimizada;\n",
        "* $W_{n}$ são os pesos atuais e que deverão ser atualizados para a próxima iteração;\n",
        "* $\\alpha$ é a taxa de aprendizado (_Learning Rate_ em inglês) e diz respeito à velocidade de aprendizagem da Rede Neural.\n",
        "    * Quanto MENOR o valor de $\\alpha$ $\\Longrightarrow$ mais devagar e demorada será a convergência para o mínimo global;\n",
        "    * Quanto MAIOR o valor de $\\alpha$ $\\Longrightarrow$ mais rápido será a convergência para o mínimo, mas sem a garantia de convergência para o mínimo global.\n",
        "* $M$ é o _Momentum_, que é o artifício para acelerar a otimização (ou minimização) da _Loss Function_ $L$.\n",
        "    * Valores altos $\\Longrightarrow$ Aumenta a velocidade da aprendizagem;\n",
        "    * Valores baixos $\\Longrightarrow$ Mais tempo para aprendizagem, mas com maiores chances de se encontrar a solução ótima, evitando os mínimos locais.\n",
        "* $\\frac{\\partial L}{\\partial W_{n}}$ é a derivada da _Loss Function_ $L$ em relação ao peso $W_{n}$. Como dito anteriormente, é a contribuição do peso $W$ no Erro. Calcular $(X*\\Delta)$ é a parte mais complicada da fórmula e fizemos estes cálculos passo a passo em aulas anteriores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzuFSOV4eboI",
        "colab_type": "text"
      },
      "source": [
        "Observe a figura a seguir: O que o _Gradient Descent_ fará é encontrar o mínimo global da _loss function_, tentando ao máximo possível evitar os mínimos locais.\n",
        "\n",
        "<img src=\"https://github.com/MathMachado/Materials/blob/master/Local_and_Global_Minima.png?raw=true\" alt=\"Drawing\" width= \"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "junvtVY4eePi"
      },
      "source": [
        "___\n",
        "# **_LOSS FUNCTION_ $L$**\n",
        "\n",
        "> Como vimos anteriormente, nosso objetivo é minimizar a _Loss function_ através do _Gradient Descent_. Em outras palavras, esse processo de otimização busca, à cada iteração (_epoch_), atualizar os pesos $W$ para reduzir a _Loss Function_. As _Loss Function_ mais comuns são:\n",
        "\n",
        "* Regressão: mse ou mae;\n",
        "* Classificação: _cross-entropy_ (quando queremos probabilidades de cada observação pertencer à uma determinada classe).\n",
        "    * Classificação binária: tf.keras.losses.BinaryCrossentropy()\n",
        ";\n",
        "    * Classificação multi-classes: tf.keras.losses.CategoricalCrossentropy()\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6e4ULmJheePY"
      },
      "source": [
        "___\n",
        "# **MÉTRICAS PARA MEDIR A PERFORMANCE DAS REDES NEURAIS**\n",
        "\n",
        "* As métricas medem a qualidade das Redes Neurais e as principais são:\n",
        "    * Regressão:\n",
        "        * MAE significa \"_Mean Absolute Error_\";\n",
        "        * MSE - significa \"_Mean Square Error_\", que é a diferença entre os valores reais $Y_{i}$ e os valores previstos (ou calculados) $\\hat{Y}_{i}$:\n",
        "        * RMSE - significa \"_Root Mean Square Error_\".\n",
        "    * Classificação:\n",
        "        * Accuracy\n",
        "* Quanto mais próximo de 0 estiver MAE, MSE ou RMSE, melhor a Rede Neural. Quanto maior a accuracy, melhor a Rede Neural.\n",
        "\n",
        "\\begin{align}\n",
        "MSE &= \\frac{\\sum_{i=1}^{n}(Y_{i}-\\hat{Y}_{i})^{2}}{n} \\\\\n",
        "RMSE &= \\sqrt{MSE} \\\\\n",
        "MAE &= \\frac{\\sum_{i=1}^{n}|Y_{i}-\\hat{Y}_{i}|}{n}\n",
        "\\end{align}\n",
        "\n",
        "Para os alunos que estão com dúvidas sobre qual métrica usar, sugiro a leitura do artigo [MAE and RMSE — Which Metric is Better?](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6n4QjH1WeeO8"
      },
      "source": [
        "___\n",
        "# **_DROPOUT_**\n",
        "\n",
        "> _Dropout_ significa ignorar aleatoriamente e temporariamente um percentual $p$ de neurônios durante a fase de treinamento. Ao \"ignorar\", quero dizer que tais neurônios não serão considerados durante os processos _forward_ e _backpropagation_.\n",
        "\n",
        "* _Dropout_ força que a Rede Neural aprenda a partir dos dados, mas usando diferentes e aleatórios neurônios;\n",
        "* Recomenda-se $p = 0.20$. \n",
        "* Ao se usar _Dropout_, recomenda-se mais épocas para treinar a Redes Neurais;\n",
        "\n",
        "* Vantagens:\n",
        "    * Evita _overfitting_ - Num \"_fully connected layer_\", neurônios desenvolvem dependência durante a fase de treinamento levando ao _overfitting_. Com _dropout_ é possível reduzir um pouco desta dependência, reduzindo as chances de _overfitting_;\n",
        "\n",
        "![Dropout](https://github.com/MathMachado/Materials/blob/master/Dropout.png?raw=true)\n",
        "\n",
        "Fonte: [Dropout in (Deep) Machine learning](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-_dropout_-in-deep-machine-learning-74334da4bfc5).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
        "\n",
        "https://towardsdatascience.com/a-guide-to-neural-network-layers-with-applications-in-keras-40ccb7ebb57a\n",
        "\n",
        "\n",
        "TEMPLATE: keras.layers.Dropout(rate, noise_shape=None, seed=None)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9-9Y9562kNNU"
      },
      "source": [
        "___\n",
        "# **Rede Neural multicamada (1 _Hidden Layer_) para o Operador Lógico XOR usando _Tensorflow_/_Keras_**\n",
        "\n",
        "* **Observações**:\n",
        "    * Há vários artigos (no _medium_, por exemplo) a discutir e desenvolver Redes Neurais para o Operador Lógico XOR. Então porque eu decidi produzir esta aula usando o dataframe do Operador Lógico XOR?\n",
        "        * Para explicar didaticamente e passo a passo todos os aspectos matemáticos por trás das Redes Neurais usando um dataframe pequeno e, apesar disso, complexo, pois é um problema linearmente NÃO-separável e, sendo assim, requer uma Rede Neural mais complexa (com pelo menos 1 _Hidden Layer_) para melhorar a acurácia e reduzir a _loss_;\n",
        "        * Para explicar como é fácil desenvolver Redes Neurais usando Tensorflow/Keras;\n",
        "        * Para explicar didaticamente e passo a passo os processos _Forward_ e _Backward_ para treinar Redes Neurais;\n",
        "    * Versão do Tensorflow usada: 2.x;\n",
        "    * Estou a utilizar o Google Colab;\n",
        "    * Nesta aula, não se preocupe demasiadamente com a sintaxe dos comandos. Porque?\n",
        "        * Vamos repetir tudo detalhadamente nas próximas aulas. Portanto, você terá a oportunidade de aprender e praticar muito em breve;\n",
        "        * O objetivo desta aula é simplesmente fazer uma introdução às Redes Neurais, Tensorflow/Keras e mostrar os passos/processos que vamos seguir aqui e no futuro para desenvolver Redes Neurais. Quando você assistir as aulas subsequentes, tudo ficará mais claro.\n",
        "* Todas as aulas do curso de Redes Neurais foram cuidadosamente planejadas e preparadas para trazer conteúdos relevantes para você aprender Redes Neurais no menor tempo possível. Portanto, nesta aula você vai encontrar várias linhas como a linha adiante:\n",
        "\n",
        "[**Python**] - Comando ou _code_ que deve ser executado.\n",
        "\n",
        "Estas linhas são uma espécie de _guide_ para não nos esquecermos de nenhum detalhe da aula. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOQbXbCgZZRL",
        "colab_type": "text"
      },
      "source": [
        "A seguir, dataframe do Operador Lógico XOR:\n",
        "\n",
        "| i | $X_{1}$ | $X_{2}$ | ValorReal ($Y_{i}$)|\n",
        "|---|---|---|---|\n",
        "| 0 | 0 | 0 | 0 |\n",
        "| 1 | 0 | 1 | 1 |\n",
        "| 2 | 1 | 0 | 1 |\n",
        "| 3 | 1 | 1 | 0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KusCpN1S4CtH",
        "colab_type": "text"
      },
      "source": [
        "Vamos obedecer os _steps_ a seguir para construir nossa Rede Neural:\n",
        "\n",
        "1. Carregar as bibliotecas do Python e Tensorflow;\n",
        "2. Carregar os dados para treinar a Rede Neural;\n",
        "3. Definir a arquitetura da Rede Neural com Tensorflow/Keras;\n",
        "4. Compilar a Rede Neural;\n",
        "5. Ajustar a Rede Neural;\n",
        "6. Avaliar a performance da Rede Neural;\n",
        "7. _Fine tuning_ da Rede Neural;\n",
        "8. Fazer Predições com a Rede Neural;\n",
        "9. Conclusões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq7pF8854cf6",
        "colab_type": "text"
      },
      "source": [
        "### 1. Carregar as bibliotecas do Python e Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br4REluttJXH",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Importar as bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-1jl_vnP7n3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UA_bHIYOrNwy"
      },
      "source": [
        "[**Python**] - Verificar a versão do Tensorflow\n",
        "> Assegurar que está a utilizar a versão 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApSwaqVbQVGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH37RXFLtPpB",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir o número de casas decimais= 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzdu5btatTom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision= 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YbKhVkd4sm2",
        "colab_type": "text"
      },
      "source": [
        "### 2. Carregar os dados para treinar a Rede Neural\n",
        "\n",
        "Segue abaixo o dataframe do Operador Lógico XOR:\n",
        "\n",
        "| i | $X_{1}$ | $X_{2}$ | ValorReal ($Y_{i}$)|\n",
        "|---|---|---|---|\n",
        "| 0 | 0 | 0 | 0 |\n",
        "| 1 | 0 | 1 | 1 |\n",
        "| 2 | 1 | 0 | 1 |\n",
        "| 3 | 1 | 1 | 0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uojCCMaWgtI",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir as entradas (_inputs_) $X$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTbtpKKdQh9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_XOR= np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "X_XOR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hc1pYW-WsCp",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir os _Outputs_ $Y$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj4zl-JdQ0nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_XOR= np.array([[0], [1], [1], [0]])\n",
        "Y_XOR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WF73gTMZtN-",
        "colab_type": "text"
      },
      "source": [
        "### 3. Conceito importante: _Fully connected layer_\n",
        "\n",
        "> A arquitetura da Rede Neural abaixo é dita _fully connected_, ou seja, os neurônios da camada anterior se conecta com todos os neurônios da camada subsequente. Observe a figura a seguir:\n",
        "\n",
        "<img src=\"https://github.com/MathMachado/Materials/blob/master/RNA_Multicamada.png?raw=true\" alt=\"Drawing\" width= \"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X5eys3mxsl2",
        "colab_type": "text"
      },
      "source": [
        "#### Arquitetura da Rede Neural\n",
        "\n",
        "> A seguir, a arquitetura da Rede Neural que vamos desenvolver neste exemplo:\n",
        "\n",
        "<img src=\"https://github.com/MathMachado/Materials/blob/master/RNA_Generic1.png?raw=true\" alt=\"Drawing\" width= \"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpmtGEFgWzhk",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir a arquitetura, ou seja:\n",
        "* $N_{I}$: Número de neurônios na camada de entrada (_Input Layer_);\n",
        "* $N_{O}$: Número de neurônios na camada de saída (_Output Layer_);\n",
        "* $N_{H}$: Número de neurônios na camada escondida (_Hidden Layer_);\n",
        "* FA: Função de ativação:\n",
        "    * _Hidden Layer_: Há várias opções que podem ser usadas, mas vou tentar resolver este exemplo com a função de ativação _Sigmoid_, que foi a função de ativação que foi a opção escolhida quando explicamos Redes Neurais passo a passo.\n",
        "    * _Output Layer_: Os valores de $Y_{i}$ do dataframe são binários. Portanto, nossa opção para função de ativação para a _Output Layer_ é usar a função de ativação _Sigmoid_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id_P910LRRb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Número de Neurônios na Input Layer:\n",
        "N_I= 2\n",
        "\n",
        "# Número de neurônios na Output Layer:\n",
        "N_O= 1\n",
        "\n",
        "# Número de neurônios na Hidden Layer:\n",
        "N_H= 3\n",
        "\n",
        "# Função de Ativação da Hidden Layer:\n",
        "FA_H= tf.keras.activations.sigmoid\n",
        "\n",
        "# Função de Ativação da Output Layer\n",
        "FA_O= tf.keras.activations.sigmoid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6s9RcjLXqQm",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir as sementes para NumPy e Tensorflow:\n",
        "> Por questões de reproducibilidade de resultados, use as sementes abaixo:\n",
        "\n",
        "* NumPy: 20111974;\n",
        "* Tensorflow: 20111974;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DizOTqQR6-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(20111974)\n",
        "tf.random.set_seed(20111974)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdcdcNncYB15",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir a Rede Neural:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8KJ0f70HEwN",
        "colab_type": "text"
      },
      "source": [
        "**Observação**:\n",
        "\n",
        "* A opção kernel_constraint= tf.keras.constraints.UnitNorm() será utilizada para reduzir _overfitting_, conforme sugere o artigo [How to Reduce Overfitting Using Weight Constraints in Keras](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-neural-networks-with-weight-constraints-in-keras/);."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LYbXfEZYNcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "RN= Sequential()\n",
        "RN.add(Dense(units= N_H, input_dim= N_I, activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dense(units= N_O, activation= FA_O))\n",
        "\n",
        "# Resumo da arquitetura da Rede Neural:\n",
        "print(RN.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoA-_8A55jMW",
        "colab_type": "text"
      },
      "source": [
        "### 4. Compilar a Rede Neural\n",
        "\n",
        "> Adam é um algoritmo de otimização.\n",
        "\n",
        "Para saber mais sobre o algoritmo de otimização 'adam', consulte o artigo [Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifkjrCT6Yki6",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando modelo.compile(optimizer, loss, metrics):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdIerBPAUGbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Algoritmo_Opt= tf.keras.optimizers.Adam()\n",
        "Loss_Function= tf.keras.losses.MeanSquaredError()\n",
        "Metrics_Perf= [tf.keras.metrics.binary_accuracy]\n",
        "\n",
        "RN.compile(optimizer= Algoritmo_Opt, loss= Loss_Function, metrics= Metrics_Perf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVx2w28c5urj",
        "colab_type": "text"
      },
      "source": [
        "### 5. Ajustar a Rede Neural\n",
        "\n",
        "* 1 _Epoch_ = 1 iteração da Rede Neural, passando por todo o dataframe de treinamento, sendo que 1 iteração contempla 1 processo _Forward_ e 1 processo _Backward_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV3XwUJ8YvxE",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando modelo.fit(X_Treinamento, Y_Treinamento, epochs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45inZ8X3U0Ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist= RN.fit(X_XOR, Y_XOR, epochs= 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1bUiekR5q1E",
        "colab_type": "text"
      },
      "source": [
        "### 6. Avaliar a performance da Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBp4ctbKY8k7",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando modelo.evaluate(X_Teste, Y_Teste):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4HlrjjjVLjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RN.evaluate(X_XOR, Y_XOR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPwANO05VT5m",
        "colab_type": "text"
      },
      "source": [
        "**Resultado**: O modelo _baseline_ (modelo inicial) apresenta os seguintes resultados:\n",
        "* loss= 0.2515;\n",
        "* accuracy= 50%.\n",
        "\n",
        "* **Comentário**: A Rede Neural apresenta resultados insatisfatórios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD2pw9H754ZZ",
        "colab_type": "text"
      },
      "source": [
        "### 7. _Fine tuning_ da Rede Neural\n",
        "\n",
        "Antes de falarmos de _fine tuning_, vamos voltar a falar de CRISP-DM:\n",
        "\n",
        "CRISP-DM significa _Cross Industry Standard Process for Data Mining_ ou processos ou fases para desenvolvimento de projetos relacionados à _Data Mining_ e que tem sido muito utilizados pelos Cientistas de Dados para desenvolvimento de modelos predictivos.\n",
        "\n",
        "<img src=\"https://github.com/MathMachado/Materials/blob/master/CRISP-DM.png?raw=true\" alt=\"Drawing\" width= \"600\"/>\n",
        "\n",
        "Fonte: [The steps to a successful machine learning project](https://emba.epfl.ch/2018/04/10/steps-successful-machine-learning-project/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ssJuKF3FNA3",
        "colab_type": "text"
      },
      "source": [
        "* CRISP-DM:\n",
        "    1. _Business Understanding_ (Entendimento do Negócio)\n",
        "        * Concentra-se no entendimento dos objetivos e requisitos do projeto sob uma perspectiva de negócios e, em seguida, na conversão desse conhecimento em uma definição de problema de mineração de dados e em um plano preliminar.\n",
        "\n",
        "    2. _Data Understanding_ (Entendimento/compreensão dos dados)\n",
        "        * Está relacionado com as atividades de extração de amostras para se familiarizar com os dados, identificar problemas de qualidade, descobrir as primeiras idéias ou detectar subconjuntos interessantes para formar hipóteses de informações ocultas.\n",
        "\n",
        "    3. _Data Preparation_ (Preparação de Dados)\n",
        "\n",
        "        * Abrange todas as atividades para construir o conjunto de dados final que será dividida entre amostra de treinamento e validação do modelo preditivo.\n",
        "\n",
        "    4. _Modeling_ (Modelagem)\n",
        "\n",
        "        * Nesta fase se avalia as possíveis técnicas que podem ser aplicadas.\n",
        "\n",
        "    5. _Evaluation_ (Avaliação do modelo)\n",
        "\n",
        "        * Após a construção do modelo _baseline_ (modelo inicial) e tendo _Loss Function_ pré-definidas, avalia-se ou testa-se a performance dos modelos preditivos (Redes Neurais, no nosso caso) para garantir que o modelo generaliza. De todos os modelos testados nesta fase, devemos selecionar o modelo campeão.\n",
        "\n",
        "    6. _Deployment_ (Implantação)\n",
        "\n",
        "        * Significa implementar o código do modelo em um sistema operacional para pontuar/escorar ou categorizar novos dados à medida que surgem e criar um mecanismo para o uso dessas novas informações na solução do problema comercial original. Importante, a representação de código também deve incluir todas as etapas de preparação de dados que antecederam a modelagem, para que o modelo trate novos dados brutos da mesma maneira que durante o desenvolvimento do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrgiPmD3jw_o",
        "colab_type": "text"
      },
      "source": [
        "#### Estratégias para melhorar a acurácia da Rede Neural\n",
        "\n",
        "Nossas alternativas são:\n",
        "\n",
        "* a. Aumentar o número de neurônios na _Hidden Layer_;\n",
        "* b. Aumentar o número de _Hidden Layers_;\n",
        "* c. Aumentar o número de _Hidden Layers_ e o número de neurônios;\n",
        "* d. Alterar a função de ativação;\n",
        "* e. Aumentar o número de _epochs_;\n",
        "* f. Alterar o algoritmo de otimização (_optimizer_);\n",
        "\n",
        "Neste exemplo, depois de várias tentativas, obtive sucesso alterando os parâmetros a seguir: \n",
        "* Função de ativação: alterar para tf.keras.activations.relu;\n",
        "* Número de neurônios na camada escondida (_Hidden Layer_): aumentei para 64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V81AQ9t8IA9D",
        "colab_type": "text"
      },
      "source": [
        "#### 7.3. Definir a arquitetura da Rede Neural com Tensorflow/Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yVhR55OoaWeX"
      },
      "source": [
        "[**Python**] - Definir a arquitetura, ou seja:\n",
        "* $N_{I}$: Número de neurônios na camada de entrada (_Input Layer_);\n",
        "* $N_{O}$: Número de neurônios na camada de saída (_Output Layer_);\n",
        "* $N_{H}$: Número de neurônios na camada escondida (_Hidden Layer_);\n",
        "* FA: Função de ativação:\n",
        "    * _Hidden Layer_: tf.keras.activations.relu;\n",
        "    * _Output Layer_: Os valores de $Y_{i}$ do dataframe são binários. Portanto, nossa opção para função de ativação para a _Output Layer_ é usar a função de ativação _Sigmoid_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R26Rf7x_aWeZ",
        "colab": {}
      },
      "source": [
        "# Número de Neurônios na Input Layer:\n",
        "N_I= 2 # NÃO FOI ALTERADA!\n",
        "\n",
        "# Número de neurônios na Output Layer:\n",
        "N_O= 1 # NÃO FOI ALTERADA!\n",
        "\n",
        "# VARIÁVEIS ALTERADAS:\n",
        "# Número de neurônios na Hidden Layer:\n",
        "N_H= 64\n",
        "\n",
        "# Função de Ativação da Hidden Layer:\n",
        "FA_H= tf.keras.activations.relu\n",
        "\n",
        "# Função de Ativação da Output Layer\n",
        "FA_O= tf.keras.activations.sigmoid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LtQXjYnvIdJR"
      },
      "source": [
        "[**Python**] - Definir as sementes para NumPy e Tensorflow:\n",
        "> Por questões de reproducibilidade de resultados, use as sementes abaixo:\n",
        "\n",
        "* NumPy: 20111974;\n",
        "* Tensorflow: 20111974;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WSCCZ6BcIdJZ",
        "colab": {}
      },
      "source": [
        "np.random.seed(20111974)\n",
        "tf.random.set_seed(20111974)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MwjdTXWNawSz"
      },
      "source": [
        "[**Python**] - Definir a Rede Neural:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OWpJNRQjIRA4"
      },
      "source": [
        "**Observações**: \n",
        "\n",
        "Para evitar problemas relacionados ao _overfitting_ e _Vanishing or Exploding Gradients in Deep Neural Nets_, os artigos abaixo sugerem as seguintes opções para inicialização dos pesos $W$:\n",
        "\n",
        "* [How to Reduce Overfitting Using Weight Constraints in Keras](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-neural-networks-with-weight-constraints-in-keras/) sugere:\n",
        "    * kernel_constraint= tf.keras.constraints.UnitNorm();\n",
        "* [Deep Learning Best Practices (1) — Weight Initialization](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94) sugere:\n",
        "    * kernel_initializer= tf.keras.initializers.he_normal() para activation= 'tf.nn.relu' ou 'tf.nn.leaky_relu' e kernel_constraint= tf.keras.constraints.UnitNorm();\n",
        "* [Vanishing/ Exploding Gradients in Deep Neural Nets and solving them](https://medium.com/swlh/vanishing-exploding-gradients-in-deep-neural-nets-and-solving-them-9d6070f28b29) sugere:\n",
        "    * kernel_initializer= tf.keras.initializers.GlorotUniform();\n",
        "    * kernel_initializer= tf.keras.initializers.GlorotNormal()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "khod_vL5awS2",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "RN= Sequential()\n",
        "RN.add(Dense(units= N_H, input_dim= N_I, activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dense(units= N_O, activation= FA_O))\n",
        "\n",
        "print(RN.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8V5EygkgIRA8"
      },
      "source": [
        "#### 7.4. Compilar a Rede Neural\n",
        "\n",
        "> Adam é um algoritmo de otimização.\n",
        "\n",
        "Para saber mais sobre 'adam', consulte o artigo [Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aEgVJAInbFW0"
      },
      "source": [
        "[**Python**] - Comando modelo.compile(optimizer, loss, metrics):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRhAlexLW29o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Algoritmo_Opt= tf.keras.optimizers.Adam()\n",
        "Loss_Function= tf.keras.losses.MeanSquaredError()\n",
        "Metrics_Perf= [tf.keras.metrics.binary_accuracy]\n",
        "\n",
        "RN.compile(optimizer= Algoritmo_Opt, loss= Loss_Function, metrics= Metrics_Perf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jxpOHzSKIRA-"
      },
      "source": [
        "#### 7.5. Ajustar a Rede Neural\n",
        "\n",
        "1 _Epoch_ = 1 iteração da Rede Neural, passando por todo o dataframe de treinamento, sendo que 1 iteração contempla 1 processo _Forward_ e 1 processo _Backward_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o-1iqXLabR4O"
      },
      "source": [
        "[**Python**] - Comando modelo.fit(X_Treinamento, Y_Treinamento, epochs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqyeqpq5XGAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RN.fit(X_XOR, Y_XOR, epochs= 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C25ZV-x4IRBB"
      },
      "source": [
        "#### 7.6. Avaliar a performance da Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tCd2S65ubg_M"
      },
      "source": [
        "[**Python**] - Comando modelo.evaluate(X_Teste, Y_Teste):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8-Vr9lXXav4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RN.evaluate(X_XOR, Y_XOR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IqEhL-2Xj-t",
        "colab_type": "text"
      },
      "source": [
        "**Resultado**: O modelo após o _fine tuning_ apresenta os seguintes resultados:\n",
        "* loss= 0.1502;\n",
        "* accuracy= 100%.\n",
        "\n",
        "* **Comentário**: A Rede Neural apresenta resultados satisfatórios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZjDavkO58Pu",
        "colab_type": "text"
      },
      "source": [
        "### 8. Fazer Predições com a Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HV4HkNDcbmJ2"
      },
      "source": [
        "[**Python**] - Comando RN.predict_classes(X_Treinamento):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aum69OJENO6V",
        "colab": {}
      },
      "source": [
        "Y_Predito= RN.predict_classes(X_XOR)\n",
        "Y_Predito"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNogASabEhz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_XOR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xaBkwD15-1d",
        "colab_type": "text"
      },
      "source": [
        "### 9. Conclusões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UULwoI-9yPIs",
        "colab_type": "text"
      },
      "source": [
        "A Rede Neural final, após a fase de _fine tuning_ apresenta os resultados mostrados na sessão 7.6. Diante destes resultados, sugerimos avançarmos para a fase de _deployment_ da Rede Neural, conforme sugere o CRISP-DM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFK4SeM5TLOb",
        "colab_type": "text"
      },
      "source": [
        "### **Exercício**\n",
        "\n",
        "1. Experimente usar outras funções de ativação para a _Hidden Layer_, registre e reporte seus resultados. Para saber mais sobre quais funções de ativação podem ser usadas, consulte [Module: tf.keras.activations](https://www.tensorflow.org/api_docs/python/tf/keras/activations);\n",
        "\n",
        "2. Experimente usar outros algoritmos de otimização para treinar a Rede Neural, registre e reporte seus resultados. Para saber quais algoritmos podem ser usados, consulte [Module: tf.keras.optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers).\n",
        "\n",
        "3. Neste exemplo, usamos o algoritmo de otimização 'adam'. Consulte a documentação sobre o 'adam' no Tensorflow/Keras e você verá que a sintaxe do algoritmo é:\n",
        "\n",
        "```\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam', **kwargs\n",
        ")\n",
        "```\n",
        "\n",
        "Refaça o treinamento da Rede Neural alterando os valores da _Learning Rate_ e reporte seus resultados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pyyiNwm6eeP4"
      },
      "source": [
        "___\n",
        "# **_ACTIVATION FUNCTION_**\n",
        "\n",
        "> As funções de ativação são uma importante parte das Redes Neurais, pois permitem às Redes Neurais a lidar com a não-linearidade existente na maioria dos problemas reais.\n",
        "\n",
        "As funções de ativação (_Activation Function_ em inglês) mais usadas são:\n",
        "* _Sigmoid_;\n",
        "* ReLU (_Rectified Linear Unit_);\n",
        "* Leaky ReLU;\n",
        "* _Generalized_ ReLU;\n",
        "* Tanh;\n",
        "* _Swish_.\n",
        "\n",
        "Os artigos a seguir discutem estas principais funções de ativação:\n",
        "* [Classical Neural Net: Why/Which Activations Functions?](https://towardsdatascience.com/classical-neural-net-why-which-activations-functions-401159ba01c4);\n",
        "* [Intermediate Topics in Neural Networks](https://towardsdatascience.com/comprehensive-introduction-to-neural-network-architecture-c08c6d8e5d98);\n",
        "* [Comparison of Activation Functions for Deep Neural Networks](https://towardsdatascience.com/comparison-of-activation-functions-for-deep-neural-networks-706ac4284c8a)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7jF5SToOKYC",
        "colab_type": "text"
      },
      "source": [
        "### Funções de ativação para _Hidden Layers_:\n",
        "\n",
        "Há várias funções de ativação que podem ser utilizadas na _Hidden Layer_. As principais são:\n",
        "\n",
        "* ReLU\n",
        "    * evita e corrige o problema conhecido como _vanishing gradient problem_, que é justamente o principal ponto fraco das funções de ativação _sigmoid_ e _tanh_. Este problema acontece porque algumas derivadas são zero para metade dos valores da entrada $X= [X_{1}, X_{2}, ..., X_{n}]$, o que pode levar ao que se chama de \"neurônios mortos\";\n",
        "    * Quase todos os modelos de _Deep Learning_ hoje usam ReLU que **deve ser usada somente para _Hidden Layers_ das Redes Neurais**. \n",
        "* Leaky ReLU\n",
        "    * Alternativa melhor que ReLU;\n",
        "* _Swish_\n",
        "    * esta é outra alternativa melhor que ReLU, proposta pelo Google em 2017;\n",
        "    * alguns artigos apontam melhoria dos resultados das Redes Neurais com _Swish_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dYvHeYbN_c4",
        "colab_type": "text"
      },
      "source": [
        "### Funções de ativação para _Output Layers_:\n",
        "\n",
        "A função de ativação da _Output Layer_ depende do problema:\n",
        "\n",
        "* _Sigmoid_ para problemas de classificação binária (2 classes).\n",
        "    * Exemplo: Dataframe: Titanic, pois queremos estimar se o passageiro morreu ou sobreviveu;\n",
        "* _Softmax_ para problemas de classificação multi-classes (> 2 classes).\n",
        "    * Exemplo: Dataframe: Iris, pois queremos estimar a espécie das flores, que são versicolor, virginica e setosa;\n",
        "* _Linear_ para problemas de regressão. \n",
        "    * Exemplo: Dataframe: Boston Housing Prediction, pois queremos estimar o preço das casas em Boston, que é uma variável contínua.\n",
        "\n",
        "\n",
        "O artigo [Comparison of Activation Functions for Deep Neural Networks](https://towardsdatascience.com/comparison-of-activation-functions-for-deep-neural-networks-706ac4284c8a) compara e discute as principais funções de ativação de forma pormenorizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "clQq59rPIkvB"
      },
      "source": [
        "___\n",
        "# **EXEMPLO 1: Rede Neural para identificar o sexo a partir de peso e altura**\n",
        "\n",
        "> O dataframe a seguir contem 10.000 medidas de altura (_height_) e peso (_weight_), sendo 5.000 medidas para o sexo masculino (_males_) e 5.000 para o sexo feminino (_females_).\n",
        "\n",
        "**Objetivo**: Estimar gênero (sexo) (_Gender_, em inglês) em função das variáveis _Height_ e _Weight_.\n",
        "\n",
        "Fonte do dataframe: Kaggle (weight-height.csv).\n",
        "\n",
        "Nesta aplicação, vamos seguir os passos adiante:\n",
        "\n",
        "1. Carregar os dados;\n",
        "2. Pré-processamento e transformação dos dados;\n",
        "3. Definir as amostras de treinamento e validação;\n",
        "4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_;\n",
        "5. Compilar a Rede Neural;\n",
        "6. Ajustar a Rede Neural;\n",
        "7. Avaliar a performance da Rede Neural;\n",
        "8. _Fine tuning_ da Rede Neural;\n",
        "9. Fazer Predições com a Rede Neural;\n",
        "10. Conclusões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dh5p2GcvLQQX"
      },
      "source": [
        "### 0. Carregar as principais bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bhjAdXgab99r"
      },
      "source": [
        "[**Python**] - Importar as bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kChuTlPddNZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZX00UN5cjvM",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Verificar a versão do Tensorflow\n",
        "> Assegurar que está a utilizar a versão 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "THWNIk_FCe_g",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZgQAKqLcLX3",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir o número de casas decimais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tzKor02BCe_d",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision= 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M5V4KopjLWOL"
      },
      "source": [
        "### 1. Carregar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_cwAUW3tseE",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Carregar os dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bs87IWPtwtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Leitura do dataframe:\n",
        "df_Sexo= pd.read_csv('https://raw.githubusercontent.com/MathMachado/DataFrames/master/weight-height.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBUeMtV7tzw6",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Mostrar as primeiras 5 linhas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcH-y4amt3gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Sexo.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OSa161sPLcAw"
      },
      "source": [
        "### Pré-processamento e transformação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL2-6wpCuARF",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Construir coluna 'sexo' da seguinte forma:\n",
        "* Se Gender= 'Male' ==> sexo= 1;\n",
        "* Se Gender= 'Female' ==> sexo= 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ccImSqCqDKre",
        "colab": {}
      },
      "source": [
        "def define_label(row):\n",
        "    if row['Gender']== 'Male':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NDYamauZCq77",
        "colab": {}
      },
      "source": [
        "df_Sexo['sexo']=df_Sexo.apply(lambda row: define_label(row), axis= 1)\n",
        "df_Sexo.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqkOrJnNuZjg",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Renomear ou reescrever os nomes das colunas do dataframe em letras minúsculas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-dahUMI6DsBz",
        "colab": {}
      },
      "source": [
        "df_Sexo= df_Sexo.drop(columns= 'Gender', axis= 1)\n",
        "df_Sexo= df_Sexo.rename({'Height': 'altura', 'Weight': 'peso'}, axis= 1)\n",
        "df_Sexo.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTISVuZ4ukQO",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir os arrays X_Sexo e Y_Sexo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMTIn6Zf5LlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Sexo= df_Sexo.copy()\n",
        "X_Sexo= X_Sexo.drop(columns= ['sexo'])\n",
        "Y_Sexo= df_Sexo['sexo'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSThKwhj4LsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Sexo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiO_F95jc1_s",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Normalizar os dados - StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4myPAnSzE7-l",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "SS = StandardScaler()\n",
        "\n",
        "X_Sexo= SS.fit_transform(X_Sexo)\n",
        "X_Sexo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jJaJWuUqJCha"
      },
      "source": [
        "### 3. Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoO2iEimu4SQ",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hTCdm-F9JBGA",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Treinamento, X_Teste, Y_Treinamento, Y_Teste= train_test_split(X_Sexo, Y_Sexo, test_size= 0.1, random_state= 20111974)\n",
        "print(f'X: Treinamento=  {X_Treinamento.shape}; X: Teste=  {X_Teste.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th9CsQpB8VDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Y: Treinamento=  {Y_Treinamento.shape}; Y: Teste= {Y_Teste.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2bL-vXiULupD"
      },
      "source": [
        "### 4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zxETX6dTfyU5"
      },
      "source": [
        "[**Python**] - Definir a arquitetura, ou seja:\n",
        "* $N_{I}$: Número de neurônios na camada de entrada (_Input Layer_);\n",
        "* $N_{O}$: Número de neurônios na camada de saída (_Output Layer_);\n",
        "* $N_{H}$: Número de neurônios na camada escondida (_Hidden Layer_);\n",
        "* FA: Função de ativação;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F_MdsLicfyU6",
        "colab": {}
      },
      "source": [
        "# Número de Neurônios na Input Layer:\n",
        "N_I= 2\n",
        "\n",
        "# Número de neurônios na Output Layer:\n",
        "N_O= 1\n",
        "\n",
        "# Número de neurônios na Hidden Layer:\n",
        "N_H= 64\n",
        "\n",
        "# Função de Ativação da Hidden Layer:\n",
        "FA_H= tf.keras.activations.swish\n",
        "\n",
        "# Função de Ativação da Output Layer:\n",
        "FA_O= tf.keras.activations.swish"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SUMmDuPCcYyB"
      },
      "source": [
        "[**Python**] - Definir as sementes para NumPy e Tensorflow:\n",
        "> Por questões de reproducibilidade de resultados, use as sementes abaixo:\n",
        "\n",
        "* NumPy: 20111974;\n",
        "* Tensorflow: 20111974;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-echOBmceVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(20111974)\n",
        "tf.random.set_seed(20111974)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ZceRRdinEM2"
      },
      "source": [
        "[**Python**] - Definir a Rede Neural:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nXQsSYq2DBfI"
      },
      "source": [
        "* 1 camada _dropout_ com $p= 0.1$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFR5Kr_nDtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "RN= Sequential()\n",
        "RN.add(Dense(N_H, input_dim= N_I, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.1))\n",
        "#RN.add(Dense(N_H2, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.1))\n",
        "RN.add(Dense(units= N_O, activation= FA_O))\n",
        "\n",
        "# Resumo da arquitetura da Rede Neural\n",
        "print(RN.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4JBZf4ypGO8o"
      },
      "source": [
        "### 5. Compilar a Rede Neural\n",
        "\n",
        "Este é um problema de classificação binária (_Male_ ou _Female_). Portanto, temos:\n",
        "* optimizer= tf.keras.optimizers.Adam();\n",
        "* loss=  tf.keras.losses.MeanSquaredError() ou loss= tf.keras.losses.BinaryCrossentropy(). Particularmente, eu gosto de usar loss=  tf.keras.losses.MeanSquaredError() porque o resultado é mais intuitivo;\n",
        "* metrics= tf.keras.metrics.binary_accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "USmAuw6f00wL"
      },
      "source": [
        "[**Python**] - Comando modelo.compile(optimizer, loss, metrics):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h7KEi1_e6SSF",
        "colab": {}
      },
      "source": [
        "Algoritmo_Opt= tf.keras.optimizers.Adam()\n",
        "Loss_Function= tf.keras.losses.MeanSquaredError()\n",
        "Metrics_Perf= tf.keras.metrics.binary_accuracy\n",
        "\n",
        "RN.compile(optimizer= Algoritmo_Opt, loss= Loss_Function, metrics= Metrics_Perf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hc90EeV_GojX"
      },
      "source": [
        "### 6. Ajustar a Rede Neural\n",
        "\n",
        "Obs.: A opção callbacks abaixo implementa o conceito de _early stopping_. Esta opção vai parar o processo de treinamento da Rede Neural antes de atingirmos o númerco de _epochs_ quando o modelo pára de melhorar, medido pela métrica val_loss. O parâmetro _patience_= k significa que o processo de otimização vai parar se tivermos k _epochs_ consecutivas sem observarmos melhoria da performance da Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCCTtUh_vEFP",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando modelo.fit(X_Treinamento, Y_Treinamento, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EB91J6nrF0db",
        "colab": {}
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5, min_delta=0.001)]\n",
        "hist= RN.fit(X_Treinamento, Y_Treinamento, epochs= 100, validation_data= (X_Teste, Y_Teste), callbacks= callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "71mX1iwvHMc5",
        "colab": {}
      },
      "source": [
        "Model_Accuracy(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o-zJ6GIjHbY8",
        "colab": {}
      },
      "source": [
        "Model_Loss(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J1sL_DTrKmpq"
      },
      "source": [
        "### 7. Avaliar a performance da Rede Neural\n",
        "\n",
        "Para avaliar a a Rede Neural, simplesmente informamos as amostras de teste: X_Teste e Y_Teste. A função evaluate() vai retornar uma lista contendo 2 valores: loss e accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VckQfEFPvMa7",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando modelo.evaluate(X_Teste, Y_Teste)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rUhEiqxfKmpv",
        "colab": {}
      },
      "source": [
        "RN.evaluate(X_Teste, Y_Teste)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "agO4cGTqKmpz"
      },
      "source": [
        "A seguir, a matriz de confusão:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aLIAXu7SN7pV",
        "colab": {}
      },
      "source": [
        "Mostra_ConfusionMatrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D5zYHcGuMPZe"
      },
      "source": [
        "### 8. _Fine tuning_ da Rede Neural\n",
        "\n",
        "Para aumentar a acurácia da Rede Neural, sugiro aumentarmos o número de neurônios na _Hidden Layer_ e/ou aumentar o número de _Hidden Layers_.\n",
        "\n",
        "No entanto, obtivemos uma acurácia razoável com a Rede Neural _baseline_. Portanto, deixo como exercício para os alunos o desafio de melhorar a acurácia desta Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ISodOu-Kmp3"
      },
      "source": [
        "### 9. Fazer Predições com a Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xgdL1W4vUrN",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando:\n",
        "* RN.predict_classes(X_Treinamento);\n",
        "* RN.predict_classes(X_Teste)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qun1-vOKmp4",
        "colab": {}
      },
      "source": [
        "Y_Predito = RN.predict_classes(X_Teste)\n",
        "Y_Predito[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I7sRwTWGKmp8",
        "colab": {}
      },
      "source": [
        "Y_Teste[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AvywP0nZMtA-"
      },
      "source": [
        "### 10. Conclusões\n",
        "\n",
        "Desenvolvemos uma Rede Neural capaz de identificar Sexo (_Gender_) com acurácia= 0.9120."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RcIh4qua_eEU"
      },
      "source": [
        "___\n",
        "# **APLICAÇÃO 1 - Rede Neural para identificar espécies (Iris Dataframe)**\n",
        "\n",
        "> A seguir, vamos desenvolver uma Rede Neural usando _Tensorflow_/_Keras_ para classificar flores (Iris). Nesta aplicação, vamos seguir os passos adiante:\n",
        "\n",
        "1. Carregar os dados;\n",
        "2. Pré-processamento e transformação dos dados;\n",
        "3. Definir as amostras de treinamento e validação;\n",
        "4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_;\n",
        "5. Compilar a Rede Neural;\n",
        "6. Ajustar a Rede Neural;\n",
        "7. Avaliar a performance da Rede Neural;\n",
        "8. _Fine tuning_ da Rede Neural;\n",
        "9. Fazer Predições com a Rede Neural;\n",
        "10. Conclusões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eXRYOpPR4XF4"
      },
      "source": [
        "### 0. Carregar bibliotecas do Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa0ir9C_dgOO"
      },
      "source": [
        "[**Python**] - Importar as bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yNYF_qzydgOR",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ird1VzZudgOU"
      },
      "source": [
        "[**Python**] - Definir o número de casas decimais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lwj9CGzEdgOV",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision= 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zmN5HGLOdgOa"
      },
      "source": [
        "[**Python**] - Verificar a versão do Tensorflow\n",
        "> Assegurar que está a utilizar a versão 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VI86wuv9dgOa",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NoKZnsJpRA8o"
      },
      "source": [
        "Perfeito, estamos a usar o TensorFlow 2.x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xkLZgdkjavO-"
      },
      "source": [
        "### 1. Carregar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7LLQyA3vgBG",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Carregar os dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ACzNibyKAkx_",
        "colab": {}
      },
      "source": [
        "df_Iris= pd.read_csv('https://raw.githubusercontent.com/MathMachado/DataFrames/master/Iris.csv', index_col= 'Id')\n",
        "df_Iris.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T3Vy41RL-lAQ"
      },
      "source": [
        "[**Python**] - Corrigir ou renomear as colunas do dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xN7nBQWg-lAX",
        "colab": {}
      },
      "source": [
        "df_Iris.columns= df_Iris.columns.str.lower()\n",
        "df_Iris.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em1wLwdzvkgh",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Mostrar quantas classes há na variável-target:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QhuoPcRuA9Do",
        "colab": {}
      },
      "source": [
        "df_Iris['species'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lvWcxUvru50G"
      },
      "source": [
        "[**Python**] - Mostrar a distribuição da variável-target 'Species':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HMpJiMWJu50J",
        "colab": {}
      },
      "source": [
        "j = sns.countplot(x=\"species\", data= df_Iris)\n",
        "plt.show(j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a55-G14aa_wG"
      },
      "source": [
        "### 2. Pré-processamento e transformação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uos9OyewvyMo",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Aplicar a transformação LabelEncoder() nos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X0V0hWnBg0so",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "\n",
        "species_encoded= LE.fit_transform(df_Iris['species'])\n",
        "df_Iris= df_Iris.drop(columns= ['species'], axis= 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8L-b9gZwB4L",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir o array Y_Iris:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMp2_hJ1wGm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_Iris= tf.keras.utils.to_categorical(species_encoded)\n",
        "Y_Iris[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfFg6cWdv9El",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir o array X_Iris:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7coeWhVRjiQl",
        "colab": {}
      },
      "source": [
        "X_Iris= df_Iris.values\n",
        "X_Iris[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cUa2sJOSbUFO"
      },
      "source": [
        "### 3. Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDOw-RHux1nS",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir as amostras de treinamento e validação da Rede Neural:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJE_6w3KL_2O",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Treinamento, X_Teste, Y_Treinamento, Y_Teste= train_test_split(X_Iris, Y_Iris, test_size= 0.2, random_state= 20111974)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NKHTG5IP9nVj",
        "colab": {}
      },
      "source": [
        "print(f'X: Treinamento=  {X_Treinamento.shape}; X: Teste=  {X_Teste.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe2mHJhb-PIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Y: Treinamento=  {Y_Treinamento.shape}; Y: Teste= {Y_Teste.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wHFI_bLXPPvl"
      },
      "source": [
        "### 4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zRYoZ7hwgejR"
      },
      "source": [
        "[**Python**] - Definir a arquitetura, ou seja:\n",
        "* $N_{I}$: Número de neurônios na camada de entrada (_Input Layer_);\n",
        "* $N_{O}$: Número de neurônios na camada de saída (_Output Layer_);\n",
        "* $N_{H}$: Número de neurônios na camada escondida (_Hidden Layer_);\n",
        "* FA: Função de ativação;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mjF1haRmgejS",
        "colab": {}
      },
      "source": [
        "# Número de Neurônios na Input Layer:\n",
        "N_I= X.Treinamento.shape[1]\n",
        "\n",
        "# Número de neurônios na Output Layer:\n",
        "N_O= Y_Iris.shape[1]\n",
        "\n",
        "# Número de neurônios na Hidden Layer:\n",
        "N_H1= 32\n",
        "\n",
        "# Função de Ativação da Hidden Layer:\n",
        "FA_H= tf.nn.leaky_relu\n",
        "\n",
        "# Função de Ativação da Output Layer:\n",
        "FA_O= tf.nn.softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tGeDaB3oo02k"
      },
      "source": [
        "[**Python**] - Definir as sementes para NumPy e Tensorflow:\n",
        "> Por questões de reproducibilidade de resultados, use as sementes abaixo:\n",
        "\n",
        "* NumPy: 20111974;\n",
        "* Tensorflow: 20111974;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zGS15afAo02n",
        "colab": {}
      },
      "source": [
        "np.random.seed(20111974)\n",
        "tf.random.set_seed(20111974)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT9w2tUCo5-X",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir a Rede Neural:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nytcmC4BkSz1"
      },
      "source": [
        "**Observações**: \n",
        "\n",
        "Para evitar problemas relacionados ao _overfitting_ e _Vanishing or Exploding Gradients in Deep Neural Nets_, os artigos abaixo sugerem as seguintes opções para inicialização dos pesos $W$:\n",
        "\n",
        "* [How to Reduce Overfitting Using Weight Constraints in Keras](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-neural-networks-with-weight-constraints-in-keras/) sugere:\n",
        "    * kernel_constraint= tf.keras.constraints.UnitNorm();\n",
        "* [Deep Learning Best Practices (1) — Weight Initialization](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94) sugere:\n",
        "    * kernel_initializer= tf.keras.initializers.he_normal() para activation= 'tf.nn.relu' ou 'tf.nn.leaky_relu' e kernel_constraint= tf.keras.constraints.UnitNorm();\n",
        "* [Vanishing/ Exploding Gradients in Deep Neural Nets and solving them](https://medium.com/swlh/vanishing-exploding-gradients-in-deep-neural-nets-and-solving-them-9d6070f28b29) sugere:\n",
        "    * kernel_initializer= tf.keras.initializers.GlorotUniform();\n",
        "    * kernel_initializer= tf.keras.initializers.GlorotNormal()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LnLeLMmZoUjU",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "RN= Sequential()\n",
        "RN.add(Dense(units= N_H, input_dim= N_I, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.1))\n",
        "RN.add(Dense(units= N_O, activation= FA_O))\n",
        "\n",
        "# Resumo da arquitetura da Rede Neural\n",
        "print(RN.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3eT-EHUecTj3"
      },
      "source": [
        "### 5. Compilar a Rede Neural\n",
        "\n",
        "Este é um problema de classificação multi-classes (> 2 classes). Portanto, temos:\n",
        "* loss= tf.keras.losses.CategoricalCrossentropy()\n",
        ";\n",
        "* metrics= tf.keras.metrics.binary_accuracy;\n",
        "* optimizer= tf.keras.optimizers.Adam()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsq0aEtwyAAM",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando modelo.compile(optimizer, loss, metrics):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NDStOKqhcRf4",
        "colab": {}
      },
      "source": [
        "Algoritmo_Opt= tf.keras.optimizers.Adam()\n",
        "Loss_Function= tf.keras.losses.CategoricalCrossentropy()\n",
        "Metrics_Perf= tf.keras.metrics.binary_accuracy\n",
        "\n",
        "RN.compile(optimizer= Algoritmo_Opt, loss= Loss_Function, metrics= Metrics_Perf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hZFu65TecabN"
      },
      "source": [
        "### 6. Ajustar a Rede Neural\n",
        "\n",
        "Nesta fase, precisamos informar:\n",
        "* **Epoch**: O número de épocas é um hiperparâmetro do _Gradient Descent_ que define o número de iterações para atualizar os pesos $W$ usando o dataframe de treinamento. Uma época significa que cada amostra no dataframe de treinamento atualizou os pesos $W$ 1 vez.\n",
        "* **Batch**: número de amostras consideradas pela Rede Neural em cada _epoch_ antes da atualização dos pesos $W$;\n",
        "\n",
        "#### Exemplo\n",
        "Suponha que temos um dataframe com 1.000 linhas (instâncias) e optamos por _epoch_= 1.000 e _batch_= 5. Isso significa que o dataframe será dividido em $\\frac{1000}{5}= 200$ _batches_. Desta forma, os pesos $W$ serão atualizados a cada processamento de 200 instâncias (linhas).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "boIs266gaZt1"
      },
      "source": [
        "Obs.: A opção callbacks abaixo implementa o conceito de _early stopping_. Esta opção vai parar o processo de treinamento da Rede Neural antes de atingirmos o númerco de _epochs_ quando o modelo pára de melhorar, medido pela métrica val_loss. O parâmetro _patience_= k significa que o processo de otimização vai parar se tivermos k _epochs_ consecutivas sem observarmos melhoria da performance da Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LpR3dXRZ-jom"
      },
      "source": [
        "[**Python**] - Comando modelo.fit(X_Treinamento, Y_Treinamento, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9hDxEwHjca8V",
        "colab": {}
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3, min_delta=0.001)]\n",
        "hist= RN.fit(X_Treinamento, Y_Treinamento, epochs= 100, validation_data= (X_Teste, Y_Teste), callbacks= callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JF7EC-g82Hho",
        "colab": {}
      },
      "source": [
        "Model_Loss(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ea0HHBsY2NZ5",
        "colab": {}
      },
      "source": [
        "Model_Accuracy(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pqVJMX3xchLF"
      },
      "source": [
        "### 7. Avaliar a performance da Rede Neural\n",
        "\n",
        "Para avaliar a Rede Neural, simplesmente informamos as amostras de teste: X_Teste e Y_Teste.\n",
        "\n",
        "A função evaluate() vai retornar uma lista contendo 2 valores: loss e accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKbO1nT0yQM1",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando modelo.evaluate(X_Teste, Y_Teste)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cYqDY9V9chcZ",
        "colab": {}
      },
      "source": [
        "RN.evaluate(X_Teste, Y_Teste)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qchEpyipcnbE"
      },
      "source": [
        "### 8. Fazer Predições com a Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X2SZ5fx2_s5",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando:\n",
        "* RN.predict_classes(X_Treinamento);\n",
        "* RN.predict_classes(X_Teste)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FR6ySksLhRvR",
        "colab": {}
      },
      "source": [
        "Y_Predito= RN.predict_classes(X_Teste)\n",
        "Y_Predito"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LWnRgBbmmlA2",
        "colab": {}
      },
      "source": [
        "Y_Teste"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wjCtiKieE_TT"
      },
      "source": [
        "### Conclusões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxMzVIGzzGHH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1qjSoM5quog1"
      },
      "source": [
        "___\n",
        "# **APLICAÇÃO 2 - Rede Neural para identificar o tipo do vinho (_Red or White_)**\n",
        "\n",
        "> Nesta aplicação, vamos usar o dataframe [wine quality](https://archive.ics.uci.edu/ml/datasets/wine+quality) extraído do repositório da UCI Machine Learning Repository. Nosso objetivo é prever o tipo do vinho (red ou white) baseado nas suas propriedades químicas.\n",
        "\n",
        "Novamente, vamos desenvolver uma Rede Neural usando _Tensorflow_/_Keras_ e seguir os passos adiante:\n",
        "\n",
        "1. Carregar os dados;\n",
        "2. Pré-processamento e transformação dos dados;\n",
        "3. Definir as amostras de treinamento e validação;\n",
        "4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_;\n",
        "5. Compilar a Rede Neural;\n",
        "6. Ajustar a Rede Neural;\n",
        "7. Avaliar a performance da Rede Neural;\n",
        "8. _Fine tuning_ da Rede Neural;\n",
        "9. Fazer Predições com a Rede Neural;\n",
        "10. Conclusões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VuG8zbYS4jyx"
      },
      "source": [
        "### 0. Carregar bibliotecas do Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O3XD4otFd9Ht"
      },
      "source": [
        "[**Python**] - Importar as bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I5Ok5fhid9Hv",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZBXRTgnCd9Hz"
      },
      "source": [
        "[**Python**] - Definir o número de casas decimais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFrOyNUgd9Hz",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision= 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cGxW2zn6q8xY"
      },
      "source": [
        "[**Python**] - Verificar a versão do Tensorflow\n",
        "> Assegurar que está a utilizar a versão 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C36Z6vGD4jy8",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kWJXP5diof5G"
      },
      "source": [
        "### 1. Carregar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJJe4r_ITDzv",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Carregar os dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jIjqYXlH4tyG",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "Wine= load_wine()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5iU33wKQGrFb",
        "colab": {}
      },
      "source": [
        "df_Red= pd.read_table(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=';')\n",
        "df_Red.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Liy2KSr6HJUX",
        "colab": {}
      },
      "source": [
        "df_White= pd.read_table('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep= ';')\n",
        "df_White.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TzUnuM4TMmJ",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Mostrar o número de linhas e colunas de cada dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pHNwVRQyIwdv",
        "colab": {}
      },
      "source": [
        "print(f'Dimensão de df_Red: {df_Red.shape}; Dimensão de df_White: {df_White.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tBWzMsUHJjTU"
      },
      "source": [
        "[**Python**] - Construir a variável-target 'type_wine' (tipo do vinho):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B0WmX3FYJqMR",
        "colab": {}
      },
      "source": [
        "df_Red['type_wine']= 0\n",
        "df_White['type_wine']= 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EVUc1vbqJ0D9"
      },
      "source": [
        "[**Python**] - Empilhar os dois dataframes: df_Red e df_White:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gS9SlpvaJ2Ex",
        "colab": {}
      },
      "source": [
        "df_Wine= pd.concat([df_Red, df_White], ignore_index=True)\n",
        "df_Wine.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dM19HHENKMtq",
        "colab": {}
      },
      "source": [
        "df_Wine.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mpoNmcqpeQxO"
      },
      "source": [
        "[**Python**] - Mostrar o número de linhas e colunas do dataframe df_Wine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YJDazoMMeMet",
        "colab": {}
      },
      "source": [
        "df_Wine.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tNyjXmFzo7oe"
      },
      "source": [
        "### 2. Pré-processamento e transformação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcV_dlHsTpiP",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Renomear o nome das colunas usando letras minúsculas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jau2OybudGc0",
        "colab": {}
      },
      "source": [
        "df_Wine.columns = df_Wine.columns.str.strip().str.lower().str.replace(' ', '_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EzOWiaCFdq_C",
        "colab": {}
      },
      "source": [
        "df_Wine.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F1wgkLcvete8"
      },
      "source": [
        "[**Python**] - Estatísticas descritivas do dataframe df_Wine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A-EbHitYepeQ",
        "colab": {}
      },
      "source": [
        "df_Wine.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uRo_7tOjex3Z"
      },
      "source": [
        "####  _Missing Values Handling_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ3K_FmCUCsk",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Mostrar o número de _missing values_ no dataframe df_Wine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PODgu5B6e5qQ",
        "colab": {}
      },
      "source": [
        "df_Wine.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "szH_TGJZecXp"
      },
      "source": [
        "Como podem ver, o dataframe df_Wine não contem _missing values_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "64znO089vF_2"
      },
      "source": [
        "[**Python**] - Mostrar a distribuição da variável-target 'type_wine':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ztQ17lhWfdAu",
        "colab": {}
      },
      "source": [
        "df_Wine['type_wine'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zDRVQy5avF_4",
        "colab": {}
      },
      "source": [
        "j = sns.countplot(x=\"type_wine\", data= df_Wine)\n",
        "plt.show(j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PxexO1Uyeqnj"
      },
      "source": [
        "Como podem ver, temos 6.497 instâncias, das quais 4.898 (75%) instâncias são type_wine= 1 (_white_) e 1.599 (25%) instâncias são type_wine= 0 (_red_). Logo, trata-se de um dataframe desbalanceado. No entanto, não vou me preocupar com este assunto neste Notebook e deixo para os alunos como exercício verificar os efeitos das amostras desbalanceadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr_HZnF0UUh3",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir os arrays X_Wine e Y_Wine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HNvImi4djc-3",
        "colab": {}
      },
      "source": [
        "X_Wine= df_Wine.copy()\n",
        "X_Wine= X_Wine.drop(columns= ['type_wine'])\n",
        "Y_Wine= df_Wine['type_wine'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ViMFMd_SlE3x"
      },
      "source": [
        "[**Python**] - Normalizar os dados - StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OurlnbX3hzSb",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define o scaler \n",
        "SS = StandardScaler()\n",
        "\n",
        "# Scale o dataframe\n",
        "X_Wine = SS.fit_transform(X_Wine)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KFkJ7b4U1x3D"
      },
      "source": [
        "### 3. Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MBqzBcDL2JH4"
      },
      "source": [
        "[**Python**] - Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bCQUxbbxhVTM",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Treinamento, X_Teste, Y_Treinamento, Y_Teste = train_test_split(X_Wine, Y_Wine, test_size= 0.2, random_state= 20111974)\n",
        "print(f'X: Treinamento=  {X_Treinamento.shape}; X: Teste= {X_Teste.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHmTtQ3F9A9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Y: Treinamento=  {Y_Treinamento.shape}; Y: Teste= {Y_Teste.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pPW0aWd4jw0o"
      },
      "source": [
        "### 4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ea4WTsP-hCqS"
      },
      "source": [
        "[**Python**] - Definir a arquitetura, ou seja:\n",
        "* $N_{I}$: Número de neurônios na camada de entrada (_Input Layer_);\n",
        "* $N_{O}$: Número de neurônios na camada de saída (_Output Layer_);\n",
        "* $N_{H}$: Número de neurônios na camada escondida (_Hidden Layer_);\n",
        "* FA: Função de ativação;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y1pVFjFThCqU",
        "colab": {}
      },
      "source": [
        "# Número de Neurônios na Input Layer:\n",
        "N_I= X_Wine.shape[1]\n",
        "\n",
        "# Número de neurônios na Output Layer:\n",
        "N_O= 1\n",
        "\n",
        "# Número de neurônios na Hidden Layer:\n",
        "N_H1= 7\n",
        "\n",
        "# Função de Ativação da Hidden Layer:\n",
        "FA_H= tf.nn.leaky_relu\n",
        "\n",
        "# Função de Ativação da Output Layer:\n",
        "FA_O= tf.nn.leaky_relu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "url8178EpUNO"
      },
      "source": [
        "[**Python**] - Definir as sementes para NumPy e Tensorflow:\n",
        "> Por questões de reproducibilidade de resultados, use as sementes abaixo:\n",
        "\n",
        "* NumPy: 20111974;\n",
        "* Tensorflow: 20111974;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MU-8uWn-pUNQ",
        "colab": {}
      },
      "source": [
        "np.random.seed(20111974)\n",
        "tf.random.set_seed(20111974)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TLUirr6oXv1",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Definir a Rede Neural:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HOQIkQ3beJm",
        "colab_type": "text"
      },
      "source": [
        "**Observações**: \n",
        "\n",
        "Para evitar problemas relacionados ao _overfitting_ e _Vanishing or Exploding Gradients in Deep Neural Nets_, os artigos abaixo sugerem as seguintes opções para inicialização dos pesos $W$:\n",
        "\n",
        "* [How to Reduce Overfitting Using Weight Constraints in Keras](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-neural-networks-with-weight-constraints-in-keras/) sugere:\n",
        "    * kernel_constraint= tf.keras.constraints.UnitNorm();\n",
        "* [Deep Learning Best Practices (1) — Weight Initialization](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94) sugere:\n",
        "    * kernel_initializer= tf.keras.initializers.he_normal() para activation= 'tf.nn.relu' ou 'tf.nn.leaky_relu' e kernel_constraint= tf.keras.constraints.UnitNorm();\n",
        "* [Vanishing/ Exploding Gradients in Deep Neural Nets and solving them](https://medium.com/swlh/vanishing-exploding-gradients-in-deep-neural-nets-and-solving-them-9d6070f28b29) sugere:\n",
        "    * kernel_initializer= tf.keras.initializers.GlorotUniform();\n",
        "    * kernel_initializer= tf.keras.initializers.GlorotNormal()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bj5uJvgaj43u",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "RN= Sequential()\n",
        "RN.add(Dense(units= N_H, input_dim= N_I, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.1))\n",
        "RN.add(Dense(units= N_O, activation= FA_O))\n",
        "\n",
        "# Resumo da arquitetura da Rede Neural\n",
        "print(RN.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LTs8xbKx2O3Z"
      },
      "source": [
        "### 5. Compilar a Rede Neural\n",
        "\n",
        "Este é um problema de classificação binária (_red_ ou _white_). Portanto, temos:\n",
        "* loss=  tf.keras.losses.BinaryCrossentropy();\n",
        "* metrics= tf.keras.metrics.binary_accuracy;\n",
        "* optimizer= tf.keras.optimizers.Adam().\n",
        "\n",
        "> **Lembre-se**: se o problema fosse de classificação de multi-classes (> 2 classes), então devemos usar loss= tf.keras.losses.CategoricalCrossentropy()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kUpBKJkl07KH"
      },
      "source": [
        "[**Python**] - Comando modelo.compile(optimizer, loss, metrics):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qGZ1bKCo2L7A",
        "colab": {}
      },
      "source": [
        "Algoritmo_Opt= tf.keras.optimizers.Adam()\n",
        "Loss_Function= tf.keras.losses.BinaryCrossentropy()\n",
        "Metrics_Perf= tf.keras.metrics.binary_accuracy\n",
        "\n",
        "RN.compile(optimizer= Algoritmo_Opt, loss= Loss_Function, metrics= Metrics_Perf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jBhkSc582ROC"
      },
      "source": [
        "### 6. Ajustar a Rede Neural\n",
        "\n",
        "Obs.: A opção callbacks abaixo implementa o conceito de _early stopping_. Esta opção vai parar o processo de treinamento da Rede Neural antes de atingirmos o númerco de _epochs_ quando o modelo pára de melhorar, medido pela métrica val_loss. O parâmetro _patience_= k significa que o processo de otimização vai parar se tivermos k _epochs_ consecutivas sem observarmos melhoria da performance da Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ls8FfHz0z2lX"
      },
      "source": [
        "[**Python**] - Comando modelo.fit(X_Treinamento, Y_Treinamento, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5mpbdiuJ2d1W",
        "colab": {}
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5, min_delta=0.001)]\n",
        "hist= RN.fit(X_Treinamento, Y_Treinamento, epochs= 10, validation_data= (X_Teste, Y_Teste), callbacks= callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sALJp9FQ2WGC",
        "colab": {}
      },
      "source": [
        "Model_Accuracy(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cWR2rMLg2ZlQ",
        "colab": {}
      },
      "source": [
        "Model_Loss(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ciXdkbVr2VDG"
      },
      "source": [
        "### 7. Avaliar a performance da Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS4_cV5TyamK",
        "colab_type": "text"
      },
      "source": [
        "[**Python**] - Comando modelo.evaluate(X_Teste, Y_Teste)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hkkxiqPe2gZK",
        "colab": {}
      },
      "source": [
        "RN.evaluate(X_Teste, Y_Teste)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m8Vs47VV4RsV"
      },
      "source": [
        "A Rede Neural tem acurácia= 0.9946."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RHQoDk533TRX"
      },
      "source": [
        "[**Python**] - Comando:\n",
        "* RN.predict_classes(X_Treinamento);\n",
        "* RN.predict_classes(X_Teste)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vlWfMR-k7Qc1",
        "colab": {}
      },
      "source": [
        "Y_Predito= RN.predict_classes(X_Teste)\n",
        "Y_Predito"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mCpp-MO0nXmj"
      },
      "source": [
        "A seguir, outras medidas para avaliarmos a performance da Rede Neural:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oWF-wWfTnjQh",
        "colab": {}
      },
      "source": [
        "# Import the modules from sklearn.metrics\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MHD0CvGQnm0v",
        "colab": {}
      },
      "source": [
        "# Precision \n",
        "precision_score(Y_Teste, Y_Predito)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ERoX4BeQnosC",
        "colab": {}
      },
      "source": [
        "# Recall\n",
        "recall_score(Y_Teste, Y_Predito)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l_2bS23Inq1p",
        "colab": {}
      },
      "source": [
        "# F1 score\n",
        "f1_score(Y_Teste,Y_Predito)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rLM1BSK2QfZm"
      },
      "source": [
        "A seguir, a matriz de confusão:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bGAigaBMQfZn",
        "colab": {}
      },
      "source": [
        "Mostra_ConfusionMatrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H3yUb9tP2YfE"
      },
      "source": [
        "### 8. Fazer Predições com a Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CupPMVRo3a5q"
      },
      "source": [
        "[**Python**] - Comando:\n",
        "* RN.predict_classes(X_Treinamento);\n",
        "* RN.predict_classes(X_Teste)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GePOr4EJ3mfn",
        "colab": {}
      },
      "source": [
        "Y_Predito = RN.predict_classes(X_Teste)\n",
        "Y_Predito[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aO79VSBS3mfv",
        "colab": {}
      },
      "source": [
        "Y_Teste[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oHlDHVp_KcLn"
      },
      "source": [
        "### 10. Conclusão\n",
        "\n",
        "Desenvolvemos uma Rede Neural com 1 _Hidden Layer_ que atingiu acurácia de 0.998."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h3mgEOcXu20F"
      },
      "source": [
        "___\n",
        "# **APLICAÇÃO 3 - Rede Neural para identificar Câncer de Mama (_Breast Cancer Dataframe_)**\n",
        "\n",
        "Fonte: [Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)\n",
        "\n",
        "Vamos desenvolver uma Rede Neural usando _Tensorflow_/_Keras_ e seguir os passos adiante:\n",
        "\n",
        "1. Carregar os dados;\n",
        "2. Pré-processamento e transformação dos dados;\n",
        "3. Definir as amostras de treinamento e validação;\n",
        "4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_;\n",
        "5. Compilar a Rede Neural;\n",
        "6. Ajustar a Rede Neural;\n",
        "7. Avaliar a performance da Rede Neural;\n",
        "8. _Fine tuning_ da Rede Neural;\n",
        "9. Fazer Predições com a Rede Neural;\n",
        "10. Conclusões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QVZQ1meF9l_-"
      },
      "source": [
        "### 0. Carregar bibliotecas do Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cd4zQSkseKzv"
      },
      "source": [
        "[**Python**] - Importar as bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OzMsBroueKzx",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wJSbJx9rrBG3"
      },
      "source": [
        "[**Python**] - Verificar a versão do Tensorflow\n",
        "> Assegurar que está a utilizar a versão 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "alCVjy_JCWUo",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Ra_PjiFeKz0"
      },
      "source": [
        "[**Python**] - Definir o número de casas decimais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y4I2Eh2YeKz1",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision= 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1nXjn5KM94lI"
      },
      "source": [
        "### 1. Carregar os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ovtqPCcWBgfI",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "Cancer = load_breast_cancer()\n",
        "X_Cancer= Cancer.data\n",
        "Y_Cancer= Cancer.target\n",
        "Col_Names= Cancer.feature_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5qbOErH6Dkcu",
        "colab": {}
      },
      "source": [
        "Col_Names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "weKuFIHqDWRX",
        "colab": {}
      },
      "source": [
        "X_Cancer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9kix-c9TDY_R",
        "colab": {}
      },
      "source": [
        "Y_Cancer[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qg_IuwHp946c"
      },
      "source": [
        "### 2. Pré-processamento e transformação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7wnkuDnMlVe8"
      },
      "source": [
        "[**Python**] - Normalizar os dados - StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uVEHT9sqG9WR",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "SS = StandardScaler()\n",
        "X_Cancer = SS.fit_transform(X_Cancer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hNeVqHH295FA"
      },
      "source": [
        "### 3. Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Rbc3MwX2RDU"
      },
      "source": [
        "[**Python**] - Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xR6XSrbsFX-P",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_Treinamento, X_Teste, Y_Treinamento, Y_Teste = train_test_split(X_Cancer, Y_Cancer, test_size = 0.1, random_state = 20111974)\n",
        "print(f'X: Treinamento=  {X_Treinamento.shape}; X: Teste=  {X_Teste.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRQ8zW1m-g6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Y: Treinamento=  {Y_Treinamento.shape}; Y: Teste= {Y_Teste.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "775KoeQz95O6"
      },
      "source": [
        "### 4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fFaKVel2ilZs"
      },
      "source": [
        "[**Python**] - Definir a arquitetura, ou seja:\n",
        "* $N_{I}$: Número de neurônios na camada de entrada (_Input Layer_);\n",
        "* $N_{O}$: Número de neurônios na camada de saída (_Output Layer_);\n",
        "* $N_{H}$: Número de neurônios na camada escondida (_Hidden Layer_);\n",
        "* FA: Função de ativação;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aB7xcQFWilZs",
        "colab": {}
      },
      "source": [
        "# Número de Neurônios na Input Layer:\n",
        "N_I= X_Cancer.shape[1]\n",
        "\n",
        "# Número de neurônios na Output Layer:\n",
        "N_O= 1\n",
        "\n",
        "# Número de neurônios na Hidden Layer:\n",
        "N_H1= 16\n",
        "N_H2= 16\n",
        "N_H3= 16\n",
        "\n",
        "# Função de Ativação da Hidden Layer:\n",
        "FA_H= tf.nn.leaky_relu\n",
        "\n",
        "# Função de Ativação da Output Layer:\n",
        "FA_O= tf.nn.softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rm1PeihTRlgz"
      },
      "source": [
        "[**Python**] - Definir as sementes para NumPy e Tensorflow:\n",
        "> Por questões de reproducibilidade de resultados, use as sementes abaixo:\n",
        "\n",
        "* NumPy: 20111974;\n",
        "* Tensorflow: 20111974;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U3oTC94GRlg3",
        "colab": {}
      },
      "source": [
        "np.random.seed(20111974)\n",
        "tf.random.set_seed(20111974)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J5GBW-Ucnh9T"
      },
      "source": [
        "[**Python**] - Definir a Rede Neural:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "my2xjCniIb4J"
      },
      "source": [
        "Vamos adicionar duas camadas _Dropout_ com $p= 0.1$ para evitarmos _overfitting_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kne06wmjnTYD",
        "colab_type": "text"
      },
      "source": [
        "**Observações**: \n",
        "\n",
        "Para evitar problemas relacionados ao _overfitting_ e _Vanishing or Exploding Gradients in Deep Neural Nets_, os artigos abaixo sugerem as seguintes opções para inicialização dos pesos $W$:\n",
        "\n",
        "* [How to Reduce Overfitting Using Weight Constraints in Keras](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-neural-networks-with-weight-constraints-in-keras/) sugere:\n",
        "    * kernel_constraint= tf.keras.constraints.UnitNorm();\n",
        "* [Deep Learning Best Practices (1) — Weight Initialization](https://medium.com/usf-msds/deep-learning-best-practices-1-weight-initialization-14e5c0295b94) sugere:\n",
        "    * kernel_initializer= tf.keras.initializers.he_normal() para activation= 'tf.nn.relu' ou 'tf.nn.leaky_relu' e kernel_constraint= tf.keras.constraints.UnitNorm();\n",
        "* [Vanishing/ Exploding Gradients in Deep Neural Nets and solving them](https://medium.com/swlh/vanishing-exploding-gradients-in-deep-neural-nets-and-solving-them-9d6070f28b29) sugere:\n",
        "    * kernel_initializer= tf.keras.initializers.GlorotUniform();\n",
        "    * kernel_initializer= tf.keras.initializers.GlorotNormal()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6x7mo4dnjlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "RN= Sequential()\n",
        "RN.add(Dense(units= N_H1, input_dim= N_I, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.1))\n",
        "RN.add(Dense(units= N_H2, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.1))\n",
        "RN.add(Dense(units= N_H3, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dense(units= N_O, activation= FA_O))\n",
        "\n",
        "# Resumo da arquitetura da Rede Neural\n",
        "print(RN.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "04cKraWZ9mMb"
      },
      "source": [
        "### 5. Compilar a Rede Neural\n",
        "\n",
        "Este é um problema de classificação binária (maligno ou benigno). Portanto, temos:\n",
        "* loss= tf.keras.losses.BinaryCrossentropy();\n",
        "* metrics= tf.keras.metrics.binary_accuracy;\n",
        "* optimizer= tf.keras.optimizers.Adam()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OGRjWcsm1FM9"
      },
      "source": [
        "[**Python**] - Comando modelo.compile(optimizer, loss, metrics):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bLIoA8FrJJCx",
        "colab": {}
      },
      "source": [
        "Algoritmo_Opt= tf.keras.optimizers.Adam()\n",
        "Loss_Function= tf.keras.losses.BinaryCrossentropy()\n",
        "Metrics_Perf= tf.keras.metrics.binary_accuracy\n",
        "\n",
        "RN.compile(optimizer= Algoritmo_Opt, loss= Loss_Function, metrics= Metrics_Perf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cnL12eaF9mU6"
      },
      "source": [
        "### 6. Ajustar a Rede Neural\n",
        "\n",
        "Obs.: A opção callbacks abaixo implementa o conceito de _early stopping_. Esta opção vai parar o processo de treinamento da Rede Neural antes de atingirmos o númerco de _epochs_ quando o modelo pára de melhorar, medido pela métrica val_loss. O parâmetro _patience_= k significa que o processo de otimização vai parar se tivermos k _epochs_ consecutivas sem observarmos melhoria da performance da Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nVsziJfk0FIv"
      },
      "source": [
        "[**Python**] - Comando modelo.fit(X_Treinamento, Y_Treinamento, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apQY6cQjJb-z",
        "colab": {}
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5, min_delta=0.001)]\n",
        "hist= RN.fit(X_Treinamento, Y_Treinamento, epochs= 100, validation_data= (X_Teste, Y_Teste), callbacks= callbacks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "avd2cXpO20cY",
        "colab": {}
      },
      "source": [
        "Model_Accuracy(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FCd8xFxA25Lc",
        "colab": {}
      },
      "source": [
        "Model_Loss(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3zToEvUs-pCt"
      },
      "source": [
        "### 7. Avaliar a performance da Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IqzKH7jsymwL"
      },
      "source": [
        "[**Python**] - Comando modelo.evaluate(X_Teste, Y_Teste)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pmjuk6OqJ7zD",
        "colab": {}
      },
      "source": [
        "RN.evaluate(X_Teste, Y_Teste)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "04ZGPI6DKcnz"
      },
      "source": [
        "A seguir, a matriz de confusão:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-MZyagwaKfkM",
        "colab": {}
      },
      "source": [
        "Mostra_ConfusionMatrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KasqSFWG-pTG"
      },
      "source": [
        "### 8. _Fine tuning_ da Rede Neural\n",
        "\n",
        "Não é necessário, pois obtivemos 0.9825 de acurácia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GLxgJP3L-pdZ"
      },
      "source": [
        "### 9. Fazer Predições com a Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0iXGBnNZYb4V"
      },
      "source": [
        "[**Python**] - Comando:\n",
        "* RN.predict_classes(X_Treinamento);\n",
        "* RN.predict_classes(X_Teste)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nqBFwxg5Yb4b",
        "colab": {}
      },
      "source": [
        "Y_Predito = RN.predict_classes(X_Teste)\n",
        "Y_Predito[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4CHdWhgD-plr"
      },
      "source": [
        "### 10. Conclusões"
      ]
    }
  ]
}